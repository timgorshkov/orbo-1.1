/**
 * AI Notification Analysis Service
 * 
 * Uses GPT-4o-mini to analyze messages for:
 * - Negativity detection (conflicts, rudeness, aggressive tone)
 * - Unanswered questions detection
 * 
 * All API calls are logged to openai_api_logs with feature='notifications'
 */

import { createAdminServer } from '@/lib/server/supabaseServer';
import { openai } from './openaiClient';
import { createServiceLogger } from '@/lib/logger';

const logger = createServiceLogger('AINotificationAnalysis');

const supabaseAdmin = createAdminServer();

// Cost calculation for gpt-4o-mini
const COST_PER_1M_INPUT = 0.15;  // $0.15 per 1M input tokens
const COST_PER_1M_OUTPUT = 0.60; // $0.60 per 1M output tokens

interface Message {
  id: string;
  text: string;
  author_name: string;
  author_id: string;
  created_at: string;
  has_reply?: boolean;
}

export interface NegativeAnalysisResult {
  has_negative: boolean;
  severity: 'low' | 'medium' | 'high';
  summary: string;
  sample_messages: string[];
  tokens_used: number;
  cost_usd: number;
}

export interface UnansweredQuestionsResult {
  questions: Array<{
    text: string;
    author: string;
    author_id: string;
    timestamp: string;
    answered: boolean;
  }>;
  tokens_used: number;
  cost_usd: number;
}

/**
 * Log AI API call to database
 */
async function logAICall(params: {
  orgId: string;
  ruleId: string;
  requestType: 'notification_negativity' | 'notification_questions';
  model: string;
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
  costUsd: number;
  metadata?: Record<string, unknown>;
}): Promise<void> {
  try {
    const costRub = params.costUsd * 95;
    
    const { error } = await supabaseAdmin
      .from('openai_api_logs')
      .insert({
        org_id: params.orgId,
        created_by: null, // System/cron
        request_type: params.requestType,
        model: params.model,
        prompt_tokens: params.promptTokens,
        completion_tokens: params.completionTokens,
        total_tokens: params.totalTokens,
        cost_usd: params.costUsd,
        cost_rub: costRub,
        metadata: {
          ...params.metadata,
          feature: 'notifications',
          rule_id: params.ruleId,
        }
      });
    
    if (error) {
      logger.error({ error: error.message, rule_id: params.ruleId }, 'Failed to log AI call');
    }
  } catch (err) {
    logger.error({ error: err }, 'Exception logging AI call');
  }
}

/**
 * Calculate cost from token usage
 */
function calculateCost(promptTokens: number, completionTokens: number): number {
  const inputCost = (promptTokens / 1_000_000) * COST_PER_1M_INPUT;
  const outputCost = (completionTokens / 1_000_000) * COST_PER_1M_OUTPUT;
  return inputCost + outputCost;
}

/**
 * Analyze messages for negativity (conflicts, rudeness, aggression)
 */
export async function analyzeNegativeContent(
  messages: Message[],
  orgId: string,
  ruleId: string,
  severityThreshold: 'low' | 'medium' | 'high' = 'medium'
): Promise<NegativeAnalysisResult> {
  if (messages.length === 0) {
    return {
      has_negative: false,
      severity: 'low',
      summary: '',
      sample_messages: [],
      tokens_used: 0,
      cost_usd: 0,
    };
  }

  const systemPrompt = `–¢—ã - –º–æ–¥–µ—Ä–∞—Ç–æ—Ä —Å–æ–æ–±—â–µ—Å—Ç–≤–∞. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –Ω–µ–≥–∞—Ç–∏–≤–∞ –∏ –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–∞.

–ö—Ä–∏—Ç–µ—Ä–∏–∏ –Ω–µ–≥–∞—Ç–∏–≤–∞ (–∏—â–∏ –ª—é–±—ã–µ –∏–∑ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤):
1. –Ø–≤–Ω—ã–π –Ω–µ–≥–∞—Ç–∏–≤:
   - –†—É–≥–∞–Ω—å, –º–∞—Ç, –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è
   - –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, —É–≥—Ä–æ–∑—ã
   - –ö–æ–Ω—Ñ–ª–∏–∫—Ç—ã –º–µ–∂–¥—É —É—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏
   - –¢–æ–∫—Å–∏—á–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ

2. –°–∫—Ä—ã—Ç—ã–π –Ω–µ–≥–∞—Ç–∏–≤ –∏ –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–æ (–≤–∞–∂–Ω–æ!):
   - –ñ–∞–ª–æ–±—ã –Ω–∞ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ: "–ü–æ—á–µ–º—É –Ω–∏–∫—Ç–æ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç", "–ú–µ–Ω—è –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç"
   - –í—ã—Ä–∞–∂–µ–Ω–∏—è —Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏—è: "–û–ø—è—Ç—å —ç—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç", "–ö–∞–∫ –≤—Å–µ–≥–¥–∞..."
   - –ü–∞—Å—Å–∏–≤–Ω–∞—è –∞–≥—Ä–µ—Å—Å–∏—è: —Å–∞—Ä–∫–∞–∑–º, —è–∑–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
   - –†–∏—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã —Å –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–æ–º: "–ò —á—Ç–æ –º–Ω–µ —Ç–µ–ø–µ—Ä—å –¥–µ–ª–∞—Ç—å?!"
   - –ü—Ä–µ—Ç–µ–Ω–∑–∏–∏ –∫ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏/—É—á–∞—Å—Ç–Ω–∏–∫–∞–º

–ü—Ä–∏–º–µ—Ä—ã –Ω–µ–≥–∞—Ç–∏–≤–∞ —Ä–∞–∑–Ω–æ–π —Å–µ—Ä—å—ë–∑–Ω–æ—Å—Ç–∏:
- low: "–ü–æ—á–µ–º—É –Ω–∏–∫—Ç–æ –Ω–µ —Ä–µ–∞–≥–∏—Ä—É–µ—Ç!", "–û–ø—è—Ç—å –∑–∞–¥–µ—Ä–∂–∫–∞", "–≠—Ç–æ —É–∂–µ –Ω–µ –ø–µ—Ä–≤—ã–π —Ä–∞–∑"
- medium: "–í—ã –≤–æ–æ–±—â–µ —á–∏—Ç–∞–µ—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è?", "–ù–∞–¥–æ–µ–ª–æ –∂–¥–∞—Ç—å", "–ü–æ–ª–Ω—ã–π –±–∞—Ä–¥–∞–∫"
- high: –û—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è, —É–≥—Ä–æ–∑—ã, –ø—Ä—è–º–∞—è –∞–≥—Ä–µ—Å—Å–∏—è

–û–ø—Ä–µ–¥–µ–ª–∏ —Å–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å (severity):
- "low" - –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–æ, —Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ, –∂–∞–ª–æ–±—ã
- "medium" - —è–≤–Ω—ã–π –∫–æ–Ω—Ñ–ª–∏–∫—Ç, –≥—Ä—É–±–æ—Å—Ç—å, —Ä–µ–∑–∫–∏–µ –ø—Ä–µ—Ç–µ–Ω–∑–∏–∏
- "high" - —Å–µ—Ä—å—ë–∑–Ω—ã–µ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è, —É–≥—Ä–æ–∑—ã, –∞–≥—Ä–µ—Å—Å–∏—è

–í–ê–ñ–ù–û: –ï—Å–ª–∏ –≤–∏–¥–∏—à—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–∞, –∂–∞–ª–æ–±—ã –∏–ª–∏ –ø—Ä–µ—Ç–µ–Ω–∑–∏–∏ - —ç—Ç–æ –Ω–µ–≥–∞—Ç–∏–≤ —É—Ä–æ–≤–Ω—è "low" –º–∏–Ω–∏–º—É–º!

–í–µ—Ä–Ω–∏ JSON:
{
  "has_negative": boolean,
  "severity": "low" | "medium" | "high",
  "summary": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–∏—Ç—É–∞—Ü–∏–∏ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)",
  "problematic_indices": [–∏–Ω–¥–µ–∫—Å—ã –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π]
}`;

  const userPrompt = `–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —á–∞—Ç–µ:

${messages.map((m, i) => `[${i}] ${m.author_name}: ${m.text.slice(0, 300)}${m.text.length > 300 ? '...' : ''}`).join('\n')}

–ü–æ—Ä–æ–≥ —Å–µ—Ä—å—ë–∑–Ω–æ—Å—Ç–∏: "${severityThreshold}" (—É–≤–µ–¥–æ–º–ª—è—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä–∏ >= —ç—Ç–æ–≥–æ —É—Ä–æ–≤–Ω—è)`;

  logger.info({
    rule_id: ruleId,
    org_id: orgId,
    messages_count: messages.length,
    severity_threshold: severityThreshold
  }, 'üîÑ [AI-ANALYSIS] Starting negativity analysis');

  try {
    logger.info({
      rule_id: ruleId,
      model: 'gpt-4o-mini',
      messages_sample: messages.slice(0, 2).map(m => ({ author: m.author_name, text: m.text.slice(0, 50) }))
    }, 'üìû [AI-ANALYSIS] Calling OpenAI API');
    
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      temperature: 0.3,
      max_tokens: 300,
      response_format: { type: 'json_object' }
    });

    logger.info({
      rule_id: ruleId,
      has_response: !!completion.choices[0]?.message?.content,
      usage: completion.usage
    }, '‚úÖ [AI-ANALYSIS] OpenAI API response received');

    const responseText = completion.choices[0]?.message?.content;
    if (!responseText) {
      throw new Error('Empty AI response');
    }

    const result = JSON.parse(responseText);
    const promptTokens = completion.usage?.prompt_tokens || 0;
    const completionTokens = completion.usage?.completion_tokens || 0;
    const totalTokens = completion.usage?.total_tokens || 0;
    const costUsd = calculateCost(promptTokens, completionTokens);

    logger.info({
      rule_id: ruleId,
      has_negative: result.has_negative,
      severity: result.severity,
      summary: result.summary,
      problematic_indices: result.problematic_indices,
      raw_response: responseText.slice(0, 500), // First 500 chars for debugging
      tokens: totalTokens,
      cost_usd: costUsd
    }, 'üìä [AI-ANALYSIS] Analysis result');

    // Log API call
    await logAICall({
      orgId,
      ruleId,
      requestType: 'notification_negativity',
      model: 'gpt-4o-mini',
      promptTokens,
      completionTokens,
      totalTokens,
      costUsd,
      metadata: { messages_count: messages.length }
    });

    // Get sample messages based on problematic indices
    const problematicIndices = result.problematic_indices || [];
    const sampleMessages = problematicIndices
      .slice(0, 3)
      .map((i: number) => messages[i]?.text.slice(0, 100))
      .filter(Boolean);

    return {
      has_negative: result.has_negative,
      severity: result.severity,
      summary: result.summary || '',
      sample_messages: sampleMessages,
      tokens_used: totalTokens,
      cost_usd: costUsd,
    };
  } catch (error) {
    logger.error({ 
      error: error instanceof Error ? error.message : String(error),
      stack: error instanceof Error ? error.stack : undefined,
      rule_id: ruleId,
      org_id: orgId
    }, '‚ùå [AI-ANALYSIS] Negativity analysis failed');
    return {
      has_negative: false,
      severity: 'low',
      summary: '–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞',
      sample_messages: [],
      tokens_used: 0,
      cost_usd: 0,
    };
  }
}

/**
 * Analyze messages for unanswered questions
 */
export async function analyzeUnansweredQuestions(
  messages: Message[],
  orgId: string,
  ruleId: string,
  timeoutHours: number = 2
): Promise<UnansweredQuestionsResult> {
  if (messages.length === 0) {
    return {
      questions: [],
      tokens_used: 0,
      cost_usd: 0,
    };
  }

  logger.info({
    rule_id: ruleId,
    org_id: orgId,
    messages_count: messages.length,
    timeout_hours: timeoutHours
  }, 'üîÑ [AI-ANALYSIS] Starting unanswered questions analysis');

  const systemPrompt = `–¢—ã - –∞–Ω–∞–ª–∏—Ç–∏–∫ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞. –ù–∞–π–¥–∏ –≤–æ–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –æ—Å—Ç–∞–ª–∏—Å—å –±–µ–∑ –æ—Ç–≤–µ—Ç–∞.

–ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤–æ–ø—Ä–æ—Å–∞:
- –Ø–≤–Ω—ã–π –≤–æ–ø—Ä–æ—Å (—Å "?")
- –ü—Ä–æ—Å—å–±–∞ –æ –ø–æ–º–æ—â–∏ ("–ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ", "–ø–æ–º–æ–≥–∏—Ç–µ", "–∫—Ç–æ –∑–Ω–∞–µ—Ç")
- –ó–∞–ø—Ä–æ—Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ("–≥–¥–µ –Ω–∞–π—Ç–∏", "–∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å")

–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ç–≤–µ—Ç–∞:
- –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ—Å–ª–µ –≤–æ–ø—Ä–æ—Å–∞ –æ—Ç –¥—Ä—É–≥–æ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞
- –°–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–ª–∏ —Å—Å—ã–ª–∫—É
- –Ø–≤–Ω–æ –æ–±—Ä–∞—â–µ–Ω–æ –∫ –∞–≤—Ç–æ—Ä—É –≤–æ–ø—Ä–æ—Å–∞

–í–µ—Ä–Ω–∏ JSON:
{
  "questions": [
    {
      "index": –∏–Ω–¥–µ–∫—Å_—Å–æ–æ–±—â–µ–Ω–∏—è,
      "answered": true/false,
      "question_summary": "–∫—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑ –≤–æ–ø—Ä–æ—Å–∞"
    }
  ]
}`;

  const userPrompt = `–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –Ω–∞–π–¥–∏ –Ω–µ–æ—Ç–≤–µ—á–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã:

${messages.map((m, i) => `[${i}] ${m.author_name} (${new Date(m.created_at).toLocaleTimeString('ru')}): ${m.text.slice(0, 200)}${m.text.length > 200 ? '...' : ''}`).join('\n')}

–¢–∞–π–º–∞—É—Ç –æ—Ç–≤–µ—Ç–∞: ${timeoutHours} —á–∞—Å–æ–≤`;

  try {
    logger.info({
      rule_id: ruleId,
      model: 'gpt-4o-mini',
      messages_sample: messages.slice(0, 2).map(m => ({ author: m.author_name, text: m.text.slice(0, 50) }))
    }, 'üìû [AI-ANALYSIS] Calling OpenAI API for questions');
    
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      temperature: 0.3,
      max_tokens: 400,
      response_format: { type: 'json_object' }
    });

    logger.info({
      rule_id: ruleId,
      has_response: !!completion.choices[0]?.message?.content,
      usage: completion.usage
    }, '‚úÖ [AI-ANALYSIS] OpenAI API response received for questions');

    const responseText = completion.choices[0]?.message?.content;
    if (!responseText) {
      throw new Error('Empty AI response');
    }

    const result = JSON.parse(responseText);
    const promptTokens = completion.usage?.prompt_tokens || 0;
    const completionTokens = completion.usage?.completion_tokens || 0;
    const totalTokens = completion.usage?.total_tokens || 0;
    const costUsd = calculateCost(promptTokens, completionTokens);

    // Log API call
    await logAICall({
      orgId,
      ruleId,
      requestType: 'notification_questions',
      model: 'gpt-4o-mini',
      promptTokens,
      completionTokens,
      totalTokens,
      costUsd,
      metadata: { messages_count: messages.length, timeout_hours: timeoutHours }
    });

    // Transform results
    const questions = (result.questions || [])
      .filter((q: { answered: boolean }) => !q.answered)
      .map((q: { index: number; question_summary: string }) => {
        const msg = messages[q.index];
        if (!msg) return null;
        return {
          text: q.question_summary || msg.text.slice(0, 100),
          author: msg.author_name,
          author_id: msg.author_id,
          timestamp: msg.created_at,
          answered: false,
        };
      })
      .filter(Boolean);

    logger.info({
      rule_id: ruleId,
      unanswered_count: questions.length,
      tokens: totalTokens,
      cost_usd: costUsd
    }, 'üìä [AI-ANALYSIS] Questions analysis result');

    return {
      questions,
      tokens_used: totalTokens,
      cost_usd: costUsd,
    };
  } catch (error) {
    logger.error({ 
      error: error instanceof Error ? error.message : String(error),
      stack: error instanceof Error ? error.stack : undefined,
      rule_id: ruleId,
      org_id: orgId
    }, '‚ùå [AI-ANALYSIS] Questions analysis failed');
    return {
      questions: [],
      tokens_used: 0,
      cost_usd: 0,
    };
  }
}

